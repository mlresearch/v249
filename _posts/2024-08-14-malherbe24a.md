---
title: Implicit Neural Representation as vectorizer for classification task applied
  to diverse data structures
abstract: Implicit neural representations have recently emerged as a promising tool
  in data science research for their ability to learn complex, high-dimensional functions
  without requiring explicit equations or hand-crafted features. Here we aim to use
  these implicit neural representations weights to represent batch of data and use
  it to classify these batch based only on these weights, without any feature engineering
  on the raw data. In this study, we demonstrate that this method yields very promising
  results in data classification of several type of data, such as sound, images, videos
  or human activities, without any prior knowledge in the relative field.
openreview: VTvytANXYq
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: malherbe24a
month: 0
tex_title: Implicit Neural Representation as vectorizer for classification task applied
  to diverse data structures
firstpage: 62
lastpage: 76
page: 62-76
order: 62
cycles: false
bibtex_author: Malherbe, Thibault
author:
- given: Thibault
  family: Malherbe
date: 2024-08-14
address:
container-title: Proceedings of the 1st ContinualAI Unconference, 2023
volume: '249'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 8
  - 14
pdf: https://raw.githubusercontent.com/mlresearch/v249/main/assets/malherbe24a/malherbe24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
